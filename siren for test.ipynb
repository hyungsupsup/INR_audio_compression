{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622f1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from asteroid.metrics import get_metrics\n",
    "from asteroid.losses import pairwise_neg_sisdr, pairwise_neg_snr, singlesrc_neg_sisdr, singlesrc_neg_snr\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f6e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'C:/Users/USER/Desktop/all_mono_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요할 때만\n",
    "audio, rate = torchaudio.load(os.path.join(datapath, 'all_mono.wav'), normalize=False)\n",
    "# seconds = 2\n",
    "# for idx, i in enumerate(range(0, audio.shape[-1], rate * seconds)):\n",
    "#     torchaudio.save(os.path.join(datapath, f'all_mono_{idx}.wav'), audio[:, i:i+rate*seconds], sample_rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5020ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid\n",
    "    \n",
    "\n",
    "class SineLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias) # wx + b => convolution 또는 다른 layer로 변경, model complexity\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "\n",
    "\n",
    "class reluLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return F.relu(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = {}\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations\n",
    "\n",
    "\n",
    "class AudioFile(torch.utils.data.Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data, self.rate = torchaudio.load(filename, normalize=False)\n",
    "        self.data = self.data.transpose(-1,-2).numpy()[...,0]\n",
    "        # self.data = self.data.astype(np.float16)\n",
    "        self.timepoints = get_mgrid(len(self.data), 1)\n",
    "\n",
    "    def get_num_samples(self):\n",
    "        return self.timepoints.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        amplitude = self.data\n",
    "        amplitude = (amplitude / 32768.)\n",
    "        amplitude = torch.Tensor(amplitude).view(-1, 1)\n",
    "\n",
    "        amplitude = amplitude / amplitude.abs().max()\n",
    "        return self.timepoints, amplitude\n",
    "\n",
    "def spectrogram(wav):\n",
    "    stft = torchaudio.transforms.Spectrogram(n_fft=1024)(wav)[0]\n",
    "    stft = torchaudio.transforms.AmplitudeToDB(top_db=80)(stft).numpy()\n",
    "    stft = stft[::-1]\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    im = plt.imshow(stft)\n",
    "    plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavpath = sorted(glob(os.path.join(datapath, f'all_mono_*.wav')), key=lambda x: int(os.path.basename(x).split('.')[0].split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b182777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siren2(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net1 = SineLayer(in_features, hidden_features, is_first=True, omega_0=first_omega_0)\n",
    "        self.net2 = SineLayer(hidden_features, hidden_features, is_first=False, omega_0=hidden_omega_0)\n",
    "        self.net3 = SineLayer(hidden_features, hidden_features, is_first=False, omega_0=hidden_omega_0)\n",
    "        self.net4 = SineLayer(hidden_features, hidden_features, is_first=False, omega_0=hidden_omega_0)\n",
    "        \n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.final = final_linear\n",
    "        else:\n",
    "            self.final = SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0)\n",
    "        \n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        \n",
    "        net1 = self.net1(coords)\n",
    "        net2 = self.net2(net1) + net1\n",
    "        net3 = self.net3(net2) + net2\n",
    "        net4 = self.net4(net3) + net3\n",
    "        output = self.final(net4)\n",
    "        return output, coords\n",
    "\n",
    "total_steps = 2000\n",
    "steps_til_summary = 1000\n",
    "lr = 1e-4\n",
    "# schedule = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, 100, T_mult=1, eta_min=lr / 1000, last_epoch=- 1, verbose=False)\n",
    "# decay = torch.optim.lr_scheduler.StepLR(optim, total_steps, (1 / 1000) ** (1 / total_steps))\n",
    "\n",
    "pesq = []\n",
    "losses = []\n",
    "name = 'Siren2_15k_128_SNR_recons_'\n",
    "\n",
    "for wave in wavpath:\n",
    "    bach_audio = AudioFile(wave)\n",
    "\n",
    "    audio_siren = Siren2(in_features=1, out_features=1, hidden_features=128, \n",
    "                        hidden_layers=3, first_omega_0=15000, hidden_omega_0=200, outermost_linear=True) # quantization(다니엘 코드가 좋습니다.), hidden_features 줄이면서 hidden_layers 조절\n",
    "    audio_siren.cuda()\n",
    "    dataloader = DataLoader(bach_audio, shuffle=True, batch_size=1, pin_memory=True, num_workers=0)\n",
    "    \n",
    "    model_input, ground_truth = next(iter(dataloader))\n",
    "    model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "\n",
    "    optim = torch.optim.Adam(lr=lr, params=audio_siren.parameters())\n",
    "    decay = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=1/2**0.5, patience=20, verbose=False)\n",
    "    # optim = torch.optim.AdamW(lr=1e-4, params=audio_siren.parameters())\n",
    "    \n",
    "    minloss = torch.inf\n",
    "    with tqdm(range(total_steps)) as pbar:\n",
    "        for step in pbar:\n",
    "            optim.zero_grad()\n",
    "            model_output, coords = audio_siren(model_input)    \n",
    "            loss = singlesrc_neg_snr(model_output.squeeze(-1), ground_truth.squeeze(-1))\n",
    "            #loss = F.mse_loss(model_output, ground_truth)\n",
    "            \n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            # schedule.step(step)\n",
    "            decay.step(loss.item())\n",
    "            if step > int(total_steps * 0.9) and minloss >= loss.item():\n",
    "                minloss = loss.item()\n",
    "                best = audio_siren.state_dict()\n",
    "                # torch.save(best, os.path.join(datapath, f'{name}_best.pt'))\n",
    "    losses.append(minloss)\n",
    "    audio_siren.load_state_dict(best)\n",
    "    audio_siren.eval()\n",
    "    with torch.no_grad():\n",
    "        model_output, _ = audio_siren(model_input)\n",
    "        \n",
    "    model_output = model_output.float()\n",
    "    ground_truth = ground_truth.float()\n",
    "    torchaudio.save(os.path.join(datapath, name + os.path.basename(wave)), model_output.squeeze(-1).cpu().float(), sample_rate=rate)\n",
    "    model_output = torchaudio.functional.resample(model_output.squeeze(-1), rate, 16000).squeeze().cpu()\n",
    "    model_input = torchaudio.functional.resample(model_input.squeeze(-1), rate, 16000).squeeze().cpu()\n",
    "    \n",
    "    # model_output, _ = torchaudio.load(os.path.join(datapath, 'recons' + os.path.basename(wave)))\n",
    "    model_output = model_output.squeeze().numpy()\n",
    "    ground_truth = torchaudio.functional.resample(ground_truth.squeeze(-1), rate, 16000).squeeze().cpu()\n",
    "    pesq.append(get_metrics(model_output, ground_truth.numpy(), model_output, sample_rate=16000, metrics_list=['pesq'])['pesq'])\n",
    "    print(pesq[-1])\n",
    "\n",
    "print(max(pesq), min(pesq), np.mean(pesq))\n",
    "plt.scatter(np.arange(len(pesq)), pesq)\n",
    "plt.plot(np.ones_like(pesq) * 3)\n",
    "plt.plot(np.ones_like(pesq) * 4)\n",
    "print(pesq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12afea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [i.shape for i in audio_siren.state_dict().values()]\n",
    "def f(x):\n",
    "    res = 1.\n",
    "    for i in x:\n",
    "        res *= i\n",
    "    return res\n",
    "aa = sum([f(i) for i in aa])\n",
    "# 압축률: 원본 bitrate / 압축본 bitrate, BPS(Bit per second)\n",
    "768 / (aa * 32 / 1 / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8338668",
   "metadata": {},
   "outputs": [],
   "source": [
    "(aa * 32 / 1 / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71708970",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum(p.numel() for p in audio_siren.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d15e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dca7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = 799170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad690f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "768 / (bb * 32 / 1 / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83115e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "(bb * 32 / 1 / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089b78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861be7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate):\n",
    "    waveform = waveform\n",
    "    \n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(\"waveform\")\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "import librosa\n",
    "\n",
    "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\"):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(specgram), origin=\"lower\", aspect=\"auto\")\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "\n",
    "# Define transform\n",
    "spectrogram = T.Spectrogram(\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    center=True,\n",
    "    pad_mode=\"reflect\",\n",
    "    power=2.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a05253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1초로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/USER/Desktop/continuous-audio-representations-main/results/default/SPEECHCOMMANDS/wavegan/autodecoder/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ca3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = torchaudio.load(path + 'original_3.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(data=audio, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471bf39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(audio)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa77863",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_audio, rate = torchaudio.load(path + 'reconstruction_epoch_10000_3.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ba92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(data=recon_audio, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906758b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(recon_audio)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70641435",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = torchaudio.load('C:/Users/Yoon/Desktop/denoising1sec/Siren2_15k_200_SNR_reconsall_mono_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(data=audio, rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f619175",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(audio,48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(audio)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75ff78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2초로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22092074",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = torchaudio.load('C:/Users/USER/Desktop/siren_2sec/Siren2_15k_128_SNR_recons_all_mono_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e310a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(audio)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [i.shape for i in Siren(in_features=1, out_features=1, hidden_features=128, hidden_layers=6, first_omega_0=15000, hidden_omega_0=200, outermost_linear=True).state_dict().values()]\n",
    "def f(x):\n",
    "    res = 1.\n",
    "    for i in x:\n",
    "        res *= i\n",
    "    return res\n",
    "aa = sum([f(i) for i in aa])\n",
    "# 압축률: 원본 bitrate / 압축본 bitrate, BPS(Bit per second)\n",
    "768 / (aa * 32 / 10 / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ea9889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733fbb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb41fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5초로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db071a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = torchaudio.load('C:/Users/Yoon/Desktop/denoising5sec/all_mono_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(audio,48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602911aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(audio)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = torchaudio.load('C:/Users/Yoon/Desktop/denoising5sec/Siren2_15k_200_MSE_reconsall_mono_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(audio,48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23dd673",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(audio)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189483e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10초로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f090f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = torchaudio.load('C:/Users/Yoon/Desktop/denoising/all_mono_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faaa708",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_waveform(audio,48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(audio)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee55d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, rate = torchaudio.load('C:/Users/Yoon/Desktop/denoising/Siren2_15k_200_MSE_reconsall_mono_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80163d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e445a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio[:,0:240000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2274f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_waveform(audio,48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d88916",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(audio)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fecc451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c6fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오디오 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Yoon/Desktop/siren_1sec_recon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavpath = sorted(glob(os.path.join(datapath, f'Siren2_15k_200_SNR_reconsall_mono_*.wav')), key=lambda x: int(os.path.basename(x).split('.')[0].split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65577a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for wave in wavpath:\n",
    "    audio, rate = torchaudio.load(wave)\n",
    "    list.append(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.cat(list,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(data=pred, rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(pred,48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = spectrogram(pred)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc15c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
